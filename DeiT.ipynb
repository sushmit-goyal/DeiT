{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-output": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "5B_rluod_Sq4",
        "outputId": "f9983c7a-a6d4-42aa-c082-f583ab9d120e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wtfml\r\n",
            "  Downloading wtfml-0.0.2-py3-none-any.whl (8.1 kB)\r\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/lib/python3.7/site-packages (from wtfml) (0.22.2.post1)\r\n",
            "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml) (0.14.1)\r\n",
            "Requirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml) (1.18.1)\r\n",
            "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml) (1.4.1)\r\n",
            "Installing collected packages: wtfml\r\n",
            "Successfully installed wtfml-0.0.2\r\n",
            "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
            "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
            "Collecting pretrainedmodels\r\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\r\n",
            "\u001b[K     |████████████████████████████████| 58 kB 1.9 MB/s \r\n",
            "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (1.5.0)\r\n",
            "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (0.6.0a0+82fd1c8)\r\n",
            "Requirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (2.5.0)\r\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (4.45.0)\r\n",
            "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (0.18.2)\r\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (1.18.1)\r\n",
            "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (5.4.1)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels) (1.14.0)\r\n",
            "Building wheels for collected packages: pretrainedmodels\r\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=e380a7b8cfe5abeb8defa0271e4ba0a643da21f521e2c18af97d7f4e82a94dd7\r\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\r\n",
            "Successfully built pretrainedmodels\r\n",
            "Installing collected packages: pretrainedmodels\r\n",
            "Successfully installed pretrainedmodels-0.7.4\r\n",
            "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
            "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
          ]
        }
      ],
      "source": [
        "!pip install wtfml\n",
        "!pip install pretrainedmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "ETqyvF1u_Sq7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import albumentations\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch.nn as nn\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from wtfml.utils import EarlyStopping\n",
        "from wtfml.engine import Engine\n",
        "from wtfml.data_loaders.image import ClassificationLoader\n",
        "\n",
        "import pretrainedmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp12t1Qb_Sq7"
      },
      "outputs": [],
      "source": [
        "class DistilledVisionTransformer(VisionTransformer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.dist_token = nn.Parameter(torch.zeros(1, 1, self.embed_dim))\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 2, self.embed_dim))\n",
        "        self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if self.num_classes > 0 else nn.Identity()\n",
        "\n",
        "        trunc_normal_(self.dist_token, std=.02)\n",
        "        trunc_normal_(self.pos_embed, std=.02)\n",
        "        self.head_dist.apply(self._init_weights)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
        "        # with slight modifications to add the dist_token\n",
        "        B = x.shape[0]\n",
        "        x = self.patch_embed(x)\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
        "        dist_token = self.dist_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
        "\n",
        "        x = x + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        return x[:, 0], x[:, 1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, x_dist = self.forward_features(x)\n",
        "        x = self.head(x)\n",
        "        x_dist = self.head_dist(x_dist)\n",
        "        if self.training:\n",
        "            return x, x_dist\n",
        "        else:\n",
        "            # during inference, return the average of both classifier predictions\n",
        "            return (x + x_dist) / 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n",
        "    model = DistilledVisionTransformer(\n",
        "        patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
        "    model.default_cfg = _cfg()\n",
        "    if pretrained:\n",
        "        checkpoint = torch.hub.load_state_dict_from_url(\n",
        "            url=\"https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_224-df68dfff.pth\",\n",
        "            map_location=\"cpu\", check_hash=True\n",
        "        )\n",
        "        model.load_state_dict(checkpoint[\"model\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "x8O08FIr_8QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillationLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    This module wraps a standard criterion and adds an extra knowledge distillation loss by\n",
        "    taking a teacher model prediction and using it as additional supervision.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_criterion: torch.nn.Module, teacher_model: torch.nn.Module,\n",
        "                 distillation_type: str, alpha: float, tau: float):\n",
        "        super().__init__()\n",
        "        self.base_criterion = base_criterion\n",
        "        self.teacher_model = teacher_model\n",
        "        assert distillation_type in ['none', 'soft', 'hard']\n",
        "        self.distillation_type = distillation_type\n",
        "        self.alpha = alpha\n",
        "        self.tau = tau\n",
        "\n",
        "    def forward(self, inputs, outputs, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs: The original inputs that are feed to the teacher model\n",
        "            outputs: the outputs of the model to be trained. It is expected to be\n",
        "                either a Tensor, or a Tuple[Tensor, Tensor], with the original output\n",
        "                in the first position and the distillation predictions as the second output\n",
        "            labels: the labels for the base criterion\n",
        "        \"\"\"\n",
        "        outputs_kd = None\n",
        "        if not isinstance(outputs, torch.Tensor):\n",
        "            # assume that the model outputs a tuple of [outputs, outputs_kd]\n",
        "            outputs, outputs_kd = outputs\n",
        "        base_loss = self.base_criterion(outputs, labels)\n",
        "        if self.distillation_type == 'none':\n",
        "            return base_loss\n",
        "\n",
        "        if outputs_kd is None:\n",
        "            raise ValueError(\"When knowledge distillation is enabled, the model is \"\n",
        "                             \"expected to return a Tuple[Tensor, Tensor] with the output of the \"\n",
        "                             \"class_token and the dist_token\")\n",
        "        # don't backprop throught the teacher\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs = self.teacher_model(inputs)\n",
        "\n",
        "        if self.distillation_type == 'soft':\n",
        "            T = self.tau\n",
        "            # taken from https://github.com/peterliht/knowledge-distillation-pytorch/blob/master/model/net.py#L100\n",
        "            # with slight modifications\n",
        "            distillation_loss = F.kl_div(\n",
        "                F.log_softmax(outputs_kd / T, dim=1),\n",
        "                #We provide the teacher's targets in log probability because we use log_target=True \n",
        "                #(as recommended in pytorch https://github.com/pytorch/pytorch/blob/9324181d0ac7b4f7949a574dbc3e8be30abe7041/torch/nn/functional.py#L2719)\n",
        "                #but it is possible to give just the probabilities and set log_target=False. In our experiments we tried both.\n",
        "                F.log_softmax(teacher_outputs / T, dim=1),\n",
        "                reduction='sum',\n",
        "                log_target=True\n",
        "            ) * (T * T) / outputs_kd.numel()\n",
        "            #We divide by outputs_kd.numel() to have the legacy PyTorch behavior. \n",
        "            #But we also experiments output_kd.size(0) \n",
        "            #see issue 61(https://github.com/facebookresearch/deit/issues/61) for more details\n",
        "        elif self.distillation_type == 'hard':\n",
        "            distillation_loss = F.cross_entropy(outputs_kd, teacher_outputs.argmax(dim=1))\n",
        "\n",
        "        loss = base_loss * (1 - self.alpha) + distillation_loss * self.alpha\n",
        "        return loss"
      ],
      "metadata": {
        "id": "Gu-_UuPrAuBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ymfVUJP_Sq8"
      },
      "outputs": [],
      "source": [
        "# create folds\n",
        "df = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")\n",
        "df[\"kfold\"] = -1    \n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "y = df.target.values\n",
        "kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
        "    df.loc[v_, 'kfold'] = f\n",
        "\n",
        "df.to_csv(\"train_folds.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7uUtMHq_Sq9"
      },
      "outputs": [],
      "source": [
        "def train(fold):\n",
        "    training_data_path = \"../input/siic-isic-224x224-images/train/\"\n",
        "    df = pd.read_csv(\"/kaggle/working/train_folds.csv\")\n",
        "    device = \"cuda\"\n",
        "    epochs = 50\n",
        "    train_bs = 32\n",
        "    valid_bs = 16\n",
        "\n",
        "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    model = SEResnext50_32x4d(pretrained=\"imagenet\")\n",
        "    model.to(device)\n",
        "\n",
        "    mean = (0.485, 0.456, 0.406)\n",
        "    std = (0.229, 0.224, 0.225)\n",
        "    train_aug = albumentations.Compose(\n",
        "        [\n",
        "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n",
        "            albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n",
        "            albumentations.Flip(p=0.5)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    valid_aug = albumentations.Compose(\n",
        "        [\n",
        "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_images = df_train.image_name.values.tolist()\n",
        "    train_images = [os.path.join(training_data_path, i + \".png\") for i in train_images]\n",
        "    train_targets = df_train.target.values\n",
        "\n",
        "    valid_images = df_valid.image_name.values.tolist()\n",
        "    valid_images = [os.path.join(training_data_path, i + \".png\") for i in valid_images]\n",
        "    valid_targets = df_valid.target.values\n",
        "\n",
        "    train_dataset = ClassificationLoader(\n",
        "        image_paths=train_images,\n",
        "        targets=train_targets,\n",
        "        resize=None,\n",
        "        augmentations=train_aug,\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=train_bs, shuffle=True, num_workers=4\n",
        "    )\n",
        "\n",
        "    valid_dataset = ClassificationLoader(\n",
        "        image_paths=valid_images,\n",
        "        targets=valid_targets,\n",
        "        resize=None,\n",
        "        augmentations=valid_aug,\n",
        "    )\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=valid_bs, shuffle=False, num_workers=4\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        patience=3,\n",
        "        threshold=0.001,\n",
        "        mode=\"max\"\n",
        "    )\n",
        "\n",
        "    es = EarlyStopping(patience=5, mode=\"max\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = Engine.train(train_loader, model, optimizer, device=device)\n",
        "        predictions, valid_loss = Engine.evaluate(\n",
        "            valid_loader, model, device=device\n",
        "        )\n",
        "        predictions = np.vstack((predictions)).ravel()\n",
        "        auc = metrics.roc_auc_score(valid_targets, predictions)\n",
        "        print(f\"Epoch = {epoch}, AUC = {auc}\")\n",
        "        scheduler.step(auc)\n",
        "\n",
        "        es(auc, model, model_path=f\"model_fold_{fold}.bin\")\n",
        "        if es.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB7cXqZJ_Sq-"
      },
      "outputs": [],
      "source": [
        "def predict(fold):\n",
        "    test_data_path = \"../input/clothing-images/test/\"\n",
        "    df = pd.read_csv(\"../input/clothing-classification/test.csv\")\n",
        "    device = \"cuda\"\n",
        "    model_path=f\"model_fold_{fold}.bin\"\n",
        "\n",
        "    mean = (0.485, 0.456, 0.406)\n",
        "    std = (0.229, 0.224, 0.225)\n",
        "    aug = albumentations.Compose(\n",
        "        [\n",
        "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    images = df.image_name.values.tolist()\n",
        "    images = [os.path.join(test_data_path, i + \".png\") for i in images]\n",
        "    targets = np.zeros(len(images))\n",
        "\n",
        "    test_dataset = ClassificationLoader(\n",
        "        image_paths=images,\n",
        "        targets=targets,\n",
        "        resize=None,\n",
        "        augmentations=aug,\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size=16, shuffle=False, num_workers=4\n",
        "    )\n",
        "\n",
        "    model = SEResnext50_32x4d(pretrained=None)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.to(device)\n",
        "\n",
        "    predictions = Engine.predict(test_loader, model, device=device)\n",
        "    predictions = np.vstack((predictions)).ravel()\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wC2Hcgv_Sq_",
        "outputId": "21b6ff9f-26a9-4ac7-a5db-d6def42ad8d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:55<00:00,  2.33it/s, loss=0.0818]\n",
            "100%|██████████| 415/415 [00:34<00:00, 12.03it/s, loss=0.0805]\n",
            "  0%|          | 0/829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 0, AUC = 0.8667945632149042\n",
            "Validation score improved (-inf --> 0.8667945632149042). Saving model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.0664]\n",
            "100%|██████████| 415/415 [00:34<00:00, 12.09it/s, loss=0.0777]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 1, AUC = 0.8743764386720293\n",
            "Validation score improved (0.8667945632149042 --> 0.8743764386720293). Saving model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.0617]\n",
            "100%|██████████| 415/415 [00:32<00:00, 12.76it/s, loss=0.0703]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 2, AUC = 0.8964024828212875\n",
            "Validation score improved (0.8743764386720293 --> 0.8964024828212875). Saving model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:53<00:00,  2.34it/s, loss=0.0576]\n",
            "100%|██████████| 415/415 [00:33<00:00, 12.41it/s, loss=0.0732]\n",
            "  0%|          | 0/829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 3, AUC = 0.8932405229839552\n",
            "EarlyStopping counter: 1 out of 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:53<00:00,  2.35it/s, loss=0.0518]\n",
            "100%|██████████| 415/415 [00:32<00:00, 12.86it/s, loss=0.0786]\n",
            "  0%|          | 0/829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 4, AUC = 0.8729648494589345\n",
            "EarlyStopping counter: 2 out of 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:53<00:00,  2.34it/s, loss=0.0483]\n",
            "100%|██████████| 415/415 [00:33<00:00, 12.29it/s, loss=0.076]\n",
            "  0%|          | 0/829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 5, AUC = 0.8866776179727478\n",
            "EarlyStopping counter: 3 out of 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.0423]\n",
            "100%|██████████| 415/415 [00:32<00:00, 12.73it/s, loss=0.089]\n",
            "  0%|          | 0/829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 6, AUC = 0.8618113250161185\n",
            "EarlyStopping counter: 4 out of 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:53<00:00,  2.34it/s, loss=0.0524]\n",
            "100%|██████████| 415/415 [00:34<00:00, 12.18it/s, loss=0.068]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 4, AUC = 0.9042333956696563\n",
            "Validation score improved (0.9018030737281536 --> 0.9042333956696563). Saving model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:53<00:00,  2.34it/s, loss=0.0469]\n",
            "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.00773]\n",
            "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.00529]\n",
            "100%|██████████| 415/415 [00:33<00:00, 12.47it/s, loss=0.133]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 16, AUC = 0.9039406974957751\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.037]\n",
            "100%|██████████| 415/415 [00:32<00:00, 12.61it/s, loss=0.109]\n",
            "  0%|          | 0/829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 7, AUC = 0.8841071344144485\n",
            "EarlyStopping counter: 3 out of 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:53<00:00,  2.35it/s, loss=0.00793]\n",
            "100%|██████████| 415/415 [00:32<00:00, 12.69it/s, loss=0.144]\n",
            "  0%|          | 0/829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 14, AUC = 0.8788854217557353\n",
            "EarlyStopping counter: 4 out of 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:53<00:00,  2.35it/s, loss=0.0616]\n",
            "100%|██████████| 829/829 [05:52<00:00,  2.35it/s, loss=0.0518]\n",
            "100%|██████████| 415/415 [00:31<00:00, 13.14it/s, loss=0.0678]\n",
            "  0%|          | 0/829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 4, AUC = 0.8964561696583822\n",
            "EarlyStopping counter: 3 out of 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:53<00:00,  2.35it/s, loss=0.0501]\n",
            "100%|██████████| 829/829 [06:06<00:00,  2.26it/s, loss=0.0298]\n",
            "100%|██████████| 415/415 [00:34<00:00, 12.19it/s, loss=0.0826]\n",
            "  0%|          | 0/829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 8, AUC = 0.9025000131330801\n",
            "EarlyStopping counter: 3 out of 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 829/829 [05:52<00:00,  2.35it/s, loss=0.0174]\n",
            "100%|██████████| 829/829 [05:53<00:00,  2.35it/s, loss=0.0069]\n",
            "100%|██████████| 415/415 [00:33<00:00, 12.41it/s, loss=0.105]\n",
            "  0%|          | 0/829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch = 15, AUC = 0.9006206693668279\n",
            "EarlyStopping counter: 1 out of 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 42/829 [00:18<05:33,  2.36it/s, loss=0.00417]"
          ]
        }
      ],
      "source": [
        "train(0)\n",
        "train(1)\n",
        "train(2)\n",
        "train(3)\n",
        "train(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xCkfnNv_Sq_",
        "outputId": "f1449205-9240-4b2b-e6f7-88f077912e15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 687/687 [00:55<00:00, 12.36it/s]\n",
            "100%|██████████| 687/687 [00:53<00:00, 12.89it/s]\n",
            "100%|██████████| 687/687 [00:53<00:00, 12.90it/s]\n",
            "100%|██████████| 687/687 [00:53<00:00, 12.72it/s]\n",
            "100%|██████████| 687/687 [00:54<00:00, 12.72it/s]\n"
          ]
        }
      ],
      "source": [
        "p1 = predict(0)\n",
        "p2 = predict(1)\n",
        "p3 = predict(2)\n",
        "p4 = predict(3)\n",
        "p5 = predict(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgoKJRvS_Sq_"
      },
      "outputs": [],
      "source": [
        "predictions = (p1 + p2 + p3 + p4 + p5) / 5\n",
        "sample = pd.read_csv(\"../input/output.csv\")\n",
        "sample.loc[:, \"target\"] = predictions\n",
        "sample.to_csv(\"output.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Melanoma_Detection_Pytorch.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}